{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SGD_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCHpwNwqezvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''This notebook implements the Stochastic Gradient Descent classifier on\n",
        "    1. The linear dataset\n",
        "    2. The standardized linear dataset\n",
        "    3. The standardized expanded dataset\n",
        "    4. Optimal features selected from the expanded dataset'''\n",
        "\n",
        "__author__ = 'Anjana Niranjan'\n",
        "__email__ = 'anjanani@usc.edu'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlJzxcyiPSQx",
        "colab_type": "text"
      },
      "source": [
        "**Stochastic gradient descent**\n",
        "Thanks to the sklearn website for examples on the functions used in this code.\n",
        "Thanks to https://stackoverflow.com/questions/51194627/python-naive-bayes-with-cross-validation-using-gaussiannb-classifier for helping with cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJtrnCzb-dHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUjeMmP1-pa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading data\n",
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/mpr/linearTrain.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/mpr/linearTest.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuyyzDjV-xH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train.iloc[:, 1:14]\n",
        "y_train = train.iloc[:,14]\n",
        "X_test = test.iloc[:, 1:14]\n",
        "y_test = test.iloc[:, 14]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb-CoV1Be9WP",
        "colab_type": "text"
      },
      "source": [
        "Implementing the SGD classifier on the data by selecting the best parameters through grid search with cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB9mnlgE-z4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "123edafd-0d17-408f-c4ae-5344742c89ae"
      },
      "source": [
        "#Splitting data into 9 folds for cross validation\n",
        "kf = KFold(n_splits=9, random_state=None, shuffle=False)\n",
        "\n",
        "#Defining parameters for the SGD Classifier\n",
        "params = {'loss':['hinge', 'log', 'modified_huber'], 'penalty':['l1', 'l2', 'elasticnet'], 'alpha': [0.1, 0.05, 0.001]}\n",
        "clf = SGDClassifier()\n",
        "\n",
        "#Selecting the most optimal set of parameters\n",
        "gs = GridSearchCV(clf, cv=kf, param_grid=params, return_train_score=True)\n",
        "\n",
        "#Training the model\n",
        "gs.fit(X_train, y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=9, random_state=None, shuffle=False),\n",
              "             error_score=nan,\n",
              "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
              "                                     class_weight=None, early_stopping=False,\n",
              "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "                                     l1_ratio=0.15, learning_rate='optimal',\n",
              "                                     loss='hinge', max_iter=1000,\n",
              "                                     n_iter_no_change=5, n_jobs=None,\n",
              "                                     penalty='l2', power_t=0.5,\n",
              "                                     random_state=None, shuffle=True, tol=0.001,\n",
              "                                     validation_fraction=0.1, verbose=0,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'alpha': [0.1, 0.05, 0.001],\n",
              "                         'loss': ['hinge', 'log', 'modified_huber'],\n",
              "                         'penalty': ['l1', 'l2', 'elasticnet']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ-WcRwW-8Vc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88e6965b-18f1-4a55-aff1-e048dcc615fa"
      },
      "source": [
        "#Visualizing the results of the different runs and cross validation\n",
        "gs.cv_results_"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([4.88269366, 0.23129312, 0.35155728, 8.48766878, 0.32676429,\n",
              "        0.39483921, 5.9396433 , 0.39948826, 0.56472254, 4.76868131,\n",
              "        0.29030988, 0.41352773, 8.37534936, 0.40690615, 0.49437523,\n",
              "        5.79380865, 0.49674996, 0.6982033 , 3.59309406, 0.49459185,\n",
              "        0.76825942, 4.55587588, 1.13878269, 1.41840659, 3.41597687,\n",
              "        0.54346715, 0.85712255]),\n",
              " 'mean_score_time': array([0.0026101 , 0.00162625, 0.00159009, 0.00214076, 0.00157611,\n",
              "        0.00156654, 0.0020708 , 0.0015805 , 0.00158702, 0.00213432,\n",
              "        0.00159963, 0.00161121, 0.00215589, 0.00156331, 0.00163799,\n",
              "        0.00213215, 0.00162111, 0.00164755, 0.00213154, 0.00160612,\n",
              "        0.00160185, 0.00209339, 0.00160162, 0.00159666, 0.00209668,\n",
              "        0.00157825, 0.00157915]),\n",
              " 'mean_test_score': array([0.68748148, 0.77525926, 0.77977778, 0.66422222, 0.79051852,\n",
              "        0.80155556, 0.74103704, 0.79562963, 0.83585185, 0.72592593,\n",
              "        0.80066667, 0.78637037, 0.70555556, 0.81355556, 0.77844444,\n",
              "        0.70925926, 0.82525926, 0.78807407, 0.77637037, 0.76385185,\n",
              "        0.78422222, 0.78577778, 0.77607407, 0.7757037 , 0.79088889,\n",
              "        0.772     , 0.76607407]),\n",
              " 'mean_train_score': array([0.84311111, 0.94667593, 0.93921296, 0.84984259, 0.94301852,\n",
              "        0.92892593, 0.88467593, 0.96187037, 0.95596296, 0.87468519,\n",
              "        0.94832407, 0.9364537 , 0.8777037 , 0.94475926, 0.94867593,\n",
              "        0.87642593, 0.93943519, 0.93486111, 0.94435185, 0.94606481,\n",
              "        0.93096296, 0.9444537 , 0.93288889, 0.93807407, 0.94262037,\n",
              "        0.93555556, 0.92142593]),\n",
              " 'param_alpha': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.05,\n",
              "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.001,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_loss': masked_array(data=['hinge', 'hinge', 'hinge', 'log', 'log', 'log',\n",
              "                    'modified_huber', 'modified_huber', 'modified_huber',\n",
              "                    'hinge', 'hinge', 'hinge', 'log', 'log', 'log',\n",
              "                    'modified_huber', 'modified_huber', 'modified_huber',\n",
              "                    'hinge', 'hinge', 'hinge', 'log', 'log', 'log',\n",
              "                    'modified_huber', 'modified_huber', 'modified_huber'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_penalty': masked_array(data=['l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l1'},\n",
              "  {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l2'},\n",
              "  {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.1, 'loss': 'log', 'penalty': 'l1'},\n",
              "  {'alpha': 0.1, 'loss': 'log', 'penalty': 'l2'},\n",
              "  {'alpha': 0.1, 'loss': 'log', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
              "  {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
              "  {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.05, 'loss': 'hinge', 'penalty': 'l1'},\n",
              "  {'alpha': 0.05, 'loss': 'hinge', 'penalty': 'l2'},\n",
              "  {'alpha': 0.05, 'loss': 'hinge', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.05, 'loss': 'log', 'penalty': 'l1'},\n",
              "  {'alpha': 0.05, 'loss': 'log', 'penalty': 'l2'},\n",
              "  {'alpha': 0.05, 'loss': 'log', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.05, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
              "  {'alpha': 0.05, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
              "  {'alpha': 0.05, 'loss': 'modified_huber', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l1'},\n",
              "  {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l2'},\n",
              "  {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.001, 'loss': 'log', 'penalty': 'l1'},\n",
              "  {'alpha': 0.001, 'loss': 'log', 'penalty': 'l2'},\n",
              "  {'alpha': 0.001, 'loss': 'log', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
              "  {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
              "  {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'elasticnet'}],\n",
              " 'rank_test_score': array([26, 18, 13, 27,  8,  4, 22,  6,  1, 23,  5, 10, 25,  3, 14, 24,  2,\n",
              "         9, 15, 21, 12, 11, 16, 17,  7, 19, 20], dtype=int32),\n",
              " 'split0_test_score': array([0.47933333, 0.79733333, 0.88733333, 0.60333333, 0.76466667,\n",
              "        0.76133333, 0.68133333, 0.71533333, 0.81933333, 0.62      ,\n",
              "        0.76733333, 0.88533333, 0.622     , 0.77466667, 0.78533333,\n",
              "        0.608     , 0.66133333, 0.72933333, 0.71933333, 0.66733333,\n",
              "        0.72933333, 0.72333333, 0.75533333, 0.70666667, 0.77733333,\n",
              "        0.7       , 0.65266667]),\n",
              " 'split0_train_score': array([0.79591667, 0.956     , 0.94391667, 0.86075   , 0.9435    ,\n",
              "        0.92683333, 0.90641667, 0.96733333, 0.95825   , 0.89383333,\n",
              "        0.94816667, 0.9475    , 0.84316667, 0.95525   , 0.94558333,\n",
              "        0.84783333, 0.95041667, 0.95966667, 0.94      , 0.958     ,\n",
              "        0.92875   , 0.94141667, 0.9275    , 0.95758333, 0.93833333,\n",
              "        0.95241667, 0.89383333]),\n",
              " 'split1_test_score': array([0.76466667, 0.71      , 0.71533333, 0.75      , 0.69133333,\n",
              "        0.696     , 0.75      , 0.72066667, 0.72666667, 0.76466667,\n",
              "        0.714     , 0.706     , 0.778     , 0.71      , 0.69933333,\n",
              "        0.76066667, 0.74466667, 0.742     , 0.69466667, 0.72066667,\n",
              "        0.70733333, 0.7       , 0.712     , 0.67733333, 0.69733333,\n",
              "        0.728     , 0.72066667]),\n",
              " 'split1_train_score': array([0.88416667, 0.9675    , 0.9405    , 0.86466667, 0.94316667,\n",
              "        0.95233333, 0.90375   , 0.97841667, 0.97691667, 0.914     ,\n",
              "        0.96491667, 0.96433333, 0.87241667, 0.96666667, 0.961     ,\n",
              "        0.926     , 0.97041667, 0.97058333, 0.95925   , 0.97541667,\n",
              "        0.98216667, 0.96      , 0.92316667, 0.93741667, 0.95766667,\n",
              "        0.93108333, 0.97466667]),\n",
              " 'split2_test_score': array([0.54133333, 0.93666667, 0.88066667, 0.54133333, 0.93666667,\n",
              "        0.81333333, 0.782     , 0.93666667, 0.93666667, 0.704     ,\n",
              "        0.83666667, 0.84133333, 0.64533333, 0.92666667, 0.93466667,\n",
              "        0.64666667, 0.93533333, 0.93666667, 0.92933333, 0.936     ,\n",
              "        0.93666667, 0.904     , 0.93666667, 0.93666667, 0.874     ,\n",
              "        0.918     , 0.936     ]),\n",
              " 'split2_train_score': array([0.83133333, 0.91025   , 0.92283333, 0.84316667, 0.94275   ,\n",
              "        0.92566667, 0.89483333, 0.9555    , 0.94833333, 0.8975    ,\n",
              "        0.92583333, 0.94308333, 0.84558333, 0.92141667, 0.94216667,\n",
              "        0.84883333, 0.93333333, 0.93816667, 0.93741667, 0.94716667,\n",
              "        0.94191667, 0.93533333, 0.94233333, 0.91133333, 0.9385    ,\n",
              "        0.92691667, 0.94775   ]),\n",
              " 'split3_test_score': array([0.502     , 0.52133333, 0.50533333, 0.49133333, 0.57133333,\n",
              "        0.68533333, 0.572     , 0.672     , 0.57133333, 0.50466667,\n",
              "        0.56866667, 0.57133333, 0.50466667, 0.56866667, 0.54866667,\n",
              "        0.504     , 0.72533333, 0.50666667, 0.57933333, 0.46933333,\n",
              "        0.55066667, 0.55466667, 0.558     , 0.57333333, 0.56466667,\n",
              "        0.56333333, 0.56733333]),\n",
              " 'split3_train_score': array([0.86616667, 0.95308333, 0.93783333, 0.89491667, 0.94316667,\n",
              "        0.91583333, 0.87425   , 0.97008333, 0.95075   , 0.90233333,\n",
              "        0.964     , 0.95566667, 0.92133333, 0.96308333, 0.96325   ,\n",
              "        0.88      , 0.97141667, 0.96875   , 0.94833333, 0.94008333,\n",
              "        0.952     , 0.95041667, 0.95983333, 0.96758333, 0.948     ,\n",
              "        0.93783333, 0.96908333]),\n",
              " 'split4_test_score': array([0.83466667, 0.852     , 0.88733333, 0.79533333, 0.88      ,\n",
              "        1.        , 0.82866667, 0.874     , 0.98933333, 0.826     ,\n",
              "        0.84066667, 0.90466667, 0.78133333, 0.84066667, 0.908     ,\n",
              "        0.85466667, 0.99066667, 0.994     , 0.83133333, 0.832     ,\n",
              "        0.986     , 0.832     , 0.84266667, 0.82933333, 0.83133333,\n",
              "        0.83066667, 0.79666667]),\n",
              " 'split4_train_score': array([0.81383333, 0.946     , 0.93475   , 0.80091667, 0.94675   ,\n",
              "        0.883     , 0.90816667, 0.95625   , 0.95191667, 0.8555    ,\n",
              "        0.951     , 0.91775   , 0.91066667, 0.93833333, 0.943     ,\n",
              "        0.89225   , 0.84883333, 0.94      , 0.94291667, 0.95333333,\n",
              "        0.86841667, 0.944     , 0.87358333, 0.91233333, 0.94466667,\n",
              "        0.95166667, 0.76758333]),\n",
              " 'split5_test_score': array([0.91933333, 0.93533333, 0.876     , 0.85533333, 0.95333333,\n",
              "        0.90133333, 0.86666667, 0.962     , 0.97533333, 0.88133333,\n",
              "        0.95      , 0.93066667, 0.93066667, 0.896     , 0.88866667,\n",
              "        0.86533333, 0.97466667, 0.92466667, 0.99      , 0.964     ,\n",
              "        0.854     , 0.99      , 0.96866667, 0.94066667, 0.96533333,\n",
              "        0.954     , 0.972     ]),\n",
              " 'split5_train_score': array([0.84091667, 0.949     , 0.93925   , 0.80541667, 0.93408333,\n",
              "        0.91833333, 0.8345    , 0.94916667, 0.95233333, 0.83233333,\n",
              "        0.94008333, 0.90816667, 0.87866667, 0.95308333, 0.94191667,\n",
              "        0.85525   , 0.95041667, 0.82991667, 0.93466667, 0.9255    ,\n",
              "        0.92233333, 0.934     , 0.94041667, 0.89341667, 0.931     ,\n",
              "        0.92658333, 0.91816667]),\n",
              " 'split6_test_score': array([0.79933333, 0.81666667, 0.79266667, 0.62133333, 0.922     ,\n",
              "        0.90133333, 0.712     , 0.81666667, 0.97066667, 0.798     ,\n",
              "        0.80533333, 0.77866667, 0.75133333, 0.95933333, 0.82533333,\n",
              "        0.63266667, 0.86466667, 0.80266667, 0.79933333, 0.79266667,\n",
              "        0.78666667, 0.954     , 0.81733333, 0.77866667, 0.94466667,\n",
              "        0.80466667, 0.804     ]),\n",
              " 'split6_train_score': array([0.88075   , 0.94783333, 0.93733333, 0.85208333, 0.93366667,\n",
              "        0.92858333, 0.8925    , 0.95533333, 0.93808333, 0.87316667,\n",
              "        0.92808333, 0.89091667, 0.88333333, 0.93508333, 0.94725   ,\n",
              "        0.87083333, 0.91875   , 0.87425   , 0.93058333, 0.92675   ,\n",
              "        0.85833333, 0.93141667, 0.9485    , 0.93941667, 0.92966667,\n",
              "        0.94083333, 0.94333333]),\n",
              " 'split7_test_score': array([0.774     , 0.72933333, 0.72933333, 0.68866667, 0.70066667,\n",
              "        0.768     , 0.818     , 0.726     , 0.70333333, 0.74      ,\n",
              "        0.82866667, 0.70933333, 0.644     , 0.732     , 0.692     ,\n",
              "        0.83      , 0.71733333, 0.76066667, 0.70933333, 0.79733333,\n",
              "        0.756     , 0.72066667, 0.728     , 0.72933333, 0.704     ,\n",
              "        0.74      , 0.828     ]),\n",
              " 'split7_train_score': array([0.84566667, 0.93691667, 0.953     , 0.83733333, 0.95108333,\n",
              "        0.94691667, 0.85358333, 0.94916667, 0.96508333, 0.86125   ,\n",
              "        0.96125   , 0.94941667, 0.87108333, 0.95483333, 0.94983333,\n",
              "        0.88541667, 0.95366667, 0.95758333, 0.949     , 0.96141667,\n",
              "        0.96208333, 0.94875   , 0.922     , 0.95816667, 0.94825   ,\n",
              "        0.96416667, 0.94333333]),\n",
              " 'split8_test_score': array([0.57266667, 0.67866667, 0.744     , 0.63133333, 0.69466667,\n",
              "        0.68733333, 0.65866667, 0.73733333, 0.83      , 0.69466667,\n",
              "        0.89466667, 0.75      , 0.69266667, 0.914     , 0.724     ,\n",
              "        0.68133333, 0.81333333, 0.696     , 0.73466667, 0.69533333,\n",
              "        0.75133333, 0.69333333, 0.666     , 0.80933333, 0.75933333,\n",
              "        0.70933333, 0.61733333]),\n",
              " 'split8_train_score': array([0.82925   , 0.9535    , 0.9435    , 0.88933333, 0.949     ,\n",
              "        0.96283333, 0.89408333, 0.97558333, 0.962     , 0.84225   ,\n",
              "        0.95158333, 0.95125   , 0.87308333, 0.91508333, 0.94408333,\n",
              "        0.88141667, 0.95766667, 0.97483333, 0.957     , 0.92691667,\n",
              "        0.96266667, 0.95475   , 0.95866667, 0.96541667, 0.9475    ,\n",
              "        0.8885    , 0.93508333]),\n",
              " 'std_fit_time': array([0.76770598, 0.01498173, 0.01961381, 1.20570408, 0.02782039,\n",
              "        0.0377451 , 0.34601275, 0.03114205, 0.06353943, 0.20472281,\n",
              "        0.01700049, 0.02378751, 1.01892445, 0.02879241, 0.04723498,\n",
              "        0.3745877 , 0.04429315, 0.08862437, 0.51485833, 0.04738099,\n",
              "        0.10259163, 0.62427116, 0.15002348, 0.17429401, 0.61785257,\n",
              "        0.05318759, 0.10311269]),\n",
              " 'std_score_time': array([1.42238729e-03, 1.22030156e-04, 6.46181306e-05, 6.80891813e-05,\n",
              "        1.36573132e-05, 2.59052538e-05, 5.37465862e-05, 3.12986773e-05,\n",
              "        5.64618858e-05, 6.56537218e-05, 5.58369096e-05, 9.89390468e-05,\n",
              "        6.01765546e-05, 2.08161251e-05, 1.10485785e-04, 5.19437000e-05,\n",
              "        1.41096676e-04, 1.22998725e-04, 4.88903443e-05, 3.44454318e-05,\n",
              "        4.54550022e-05, 3.16693114e-05, 3.98145543e-05, 4.16590097e-05,\n",
              "        3.07921068e-05, 2.97598006e-05, 3.32118804e-05]),\n",
              " 'std_test_score': array([0.1540719 , 0.12469675, 0.11833912, 0.11219516, 0.12865603,\n",
              "        0.10534083, 0.08876275, 0.09986268, 0.13788483, 0.10681954,\n",
              "        0.10396818, 0.10936545, 0.11483364, 0.12042722, 0.117888  ,\n",
              "        0.11816768, 0.11474306, 0.14037567, 0.119056  , 0.14099112,\n",
              "        0.12210176, 0.134814  , 0.12271836, 0.11288369, 0.12077527,\n",
              "        0.11282325, 0.13082396]),\n",
              " 'std_train_score': array([0.02800893, 0.0150462 , 0.0076441 , 0.03073795, 0.00560145,\n",
              "        0.02218411, 0.02411605, 0.01052401, 0.01053317, 0.0270675 ,\n",
              "        0.01370064, 0.02338794, 0.02435929, 0.01718201, 0.00759085,\n",
              "        0.02329781, 0.03564108, 0.04699681, 0.00926078, 0.01664034,\n",
              "        0.04003392, 0.00927105, 0.02480893, 0.02533533, 0.00851932,\n",
              "        0.02050707, 0.0590524 ])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptW3kVsCdxue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c952f98e-401a-4e05-f748-97bec839410d"
      },
      "source": [
        "#The best estimator obtained by grid search\n",
        "gs.best_estimator_"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
              "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
              "              learning_rate='optimal', loss='modified_huber', max_iter=1000,\n",
              "              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
              "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur92AuR3iuH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59565eba-502c-4890-e45f-3293f8a658e9"
      },
      "source": [
        "#The best parameters\n",
        "gs.best_params_"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'elasticnet'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uxJxXp7i0HK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61e8e942-5717-4bfb-a6e6-2b3a93d83685"
      },
      "source": [
        "#The best score\n",
        "gs.best_score_"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8358518518518518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3GNabhv_B76",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "43ab4407-6a42-4d42-a783-f508f84b6319"
      },
      "source": [
        "#Running the classifier with best parameters on train data\n",
        "bestclf = SGDClassifier(alpha= 0.1, loss= 'modified_huber', penalty= 'elasticnet')\n",
        "bestclf.fit(X_train, y_train)\n",
        "tr_p = bestclf.predict(X_train)\n",
        "print(accuracy_score(y_train, tr_p))\n",
        "confusion_matrix(y_train, tr_p)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9527407407407408\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2770,    0,    2,    6,    6],\n",
              "       [   5, 2313,    8,   30,  226],\n",
              "       [   9,   12, 2416,  124,   88],\n",
              "       [   5,   29,    4, 2435,    3],\n",
              "       [   1,   78,    0,    2, 2928]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHkD9qVA_Fv6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "894f4ddf-b1d3-4e0d-c533-7d16df8ad1a3"
      },
      "source": [
        "#Running the classifier with best parameters on test data\n",
        "predictions = bestclf.predict(X_test)\n",
        "print(accuracy_score(y_test, predictions))\n",
        "confusion_matrix(y_test, predictions)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9013223375515427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4182,   48,   80,    5,  151],\n",
              "       [   0, 4267,   31,  104,    0],\n",
              "       [   5,  330, 4223,  221,    0],\n",
              "       [   0,  914,    1, 2984,   15],\n",
              "       [   0,   31,    0,  146, 3361]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWeHRP9pf9K-",
        "colab_type": "text"
      },
      "source": [
        "Running SGD on Normalized data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGuoxTNFf5Pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "scalar = preprocessing.StandardScaler()\n",
        "scalar.fit(X_train)\n",
        "X_train = scalar.transform(X_train)\n",
        "X_test = scalar.transform(X_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQY7jbD3gApb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "1195f3e1-8cb0-4b9c-c53d-fa49c0a5d8a4"
      },
      "source": [
        "kf = KFold(n_splits=9, random_state=None, shuffle=False)\n",
        "params = {'loss':['hinge', 'log', 'modified_huber'], 'penalty':['l1', 'l2', 'elasticnet'], 'alpha': [0.1, 0.05, 0.001]}\n",
        "clf = SGDClassifier()\n",
        "gs = GridSearchCV(clf, cv=kf, param_grid=params, return_train_score=True)\n",
        "\n",
        "gs.fit(X_train, y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=9, random_state=None, shuffle=False),\n",
              "             error_score=nan,\n",
              "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
              "                                     class_weight=None, early_stopping=False,\n",
              "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "                                     l1_ratio=0.15, learning_rate='optimal',\n",
              "                                     loss='hinge', max_iter=1000,\n",
              "                                     n_iter_no_change=5, n_jobs=None,\n",
              "                                     penalty='l2', power_t=0.5,\n",
              "                                     random_state=None, shuffle=True, tol=0.001,\n",
              "                                     validation_fraction=0.1, verbose=0,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'alpha': [0.1, 0.05, 0.001],\n",
              "                         'loss': ['hinge', 'log', 'modified_huber'],\n",
              "                         'penalty': ['l1', 'l2', 'elasticnet']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOoEJu8HgED6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a087b120-e6a2-41b5-e571-c18fc2e073f3"
      },
      "source": [
        "#Result of grid search\n",
        "gs.cv_results_"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.09301114, 0.0563989 , 0.09673145, 0.15190797, 0.11138956,\n",
              "        0.13686678, 0.19580939, 0.07068348, 0.11695928, 0.10166462,\n",
              "        0.05608802, 0.09329526, 0.14596992, 0.11135793, 0.13750116,\n",
              "        0.24601769, 0.08058601, 0.13465635, 0.16634295, 0.08431957,\n",
              "        0.13476833, 0.22949796, 0.141501  , 0.16993878, 0.7500538 ,\n",
              "        0.16032227, 0.27049637]),\n",
              " 'mean_score_time': array([0.00099688, 0.00102388, 0.00105023, 0.00082649, 0.00098297,\n",
              "        0.00081637, 0.00083457, 0.00104573, 0.00097508, 0.00102133,\n",
              "        0.00112012, 0.00108753, 0.00082559, 0.00109214, 0.00083595,\n",
              "        0.00082808, 0.00104417, 0.0008587 , 0.00084917, 0.0010598 ,\n",
              "        0.00080951, 0.00085473, 0.00081693, 0.00084072, 0.00085542,\n",
              "        0.00082472, 0.00087704]),\n",
              " 'mean_test_score': array([0.55666667, 0.85681481, 0.85622222, 0.7857037 , 0.81192593,\n",
              "        0.81140741, 0.86459259, 0.88148148, 0.88074074, 0.82274074,\n",
              "        0.86303704, 0.8677037 , 0.8417037 , 0.81777778, 0.81725926,\n",
              "        0.82192593, 0.91288889, 0.90874074, 0.84792593, 0.88155556,\n",
              "        0.86977778, 0.86362963, 0.86718519, 0.86711111, 0.82081481,\n",
              "        0.8317037 , 0.85340741]),\n",
              " 'mean_train_score': array([0.66698148, 0.91043519, 0.9037037 , 0.84472222, 0.8840463 ,\n",
              "        0.87696296, 0.92590741, 0.95891667, 0.95475926, 0.89655556,\n",
              "        0.93211111, 0.92427778, 0.87893519, 0.89825   , 0.89990741,\n",
              "        0.95743519, 0.9660463 , 0.96624074, 0.98057407, 0.97188889,\n",
              "        0.97290741, 0.98130556, 0.96855556, 0.97009259, 0.98196296,\n",
              "        0.97758333, 0.98024074]),\n",
              " 'param_alpha': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.05,\n",
              "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.001,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_loss': masked_array(data=['hinge', 'hinge', 'hinge', 'log', 'log', 'log',\n",
              "                    'modified_huber', 'modified_huber', 'modified_huber',\n",
              "                    'hinge', 'hinge', 'hinge', 'log', 'log', 'log',\n",
              "                    'modified_huber', 'modified_huber', 'modified_huber',\n",
              "                    'hinge', 'hinge', 'hinge', 'log', 'log', 'log',\n",
              "                    'modified_huber', 'modified_huber', 'modified_huber'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_penalty': masked_array(data=['l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l1'},\n",
              "  {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l2'},\n",
              "  {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.1, 'loss': 'log', 'penalty': 'l1'},\n",
              "  {'alpha': 0.1, 'loss': 'log', 'penalty': 'l2'},\n",
              "  {'alpha': 0.1, 'loss': 'log', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
              "  {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
              "  {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.05, 'loss': 'hinge', 'penalty': 'l1'},\n",
              "  {'alpha': 0.05, 'loss': 'hinge', 'penalty': 'l2'},\n",
              "  {'alpha': 0.05, 'loss': 'hinge', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.05, 'loss': 'log', 'penalty': 'l1'},\n",
              "  {'alpha': 0.05, 'loss': 'log', 'penalty': 'l2'},\n",
              "  {'alpha': 0.05, 'loss': 'log', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.05, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
              "  {'alpha': 0.05, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
              "  {'alpha': 0.05, 'loss': 'modified_huber', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l1'},\n",
              "  {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l2'},\n",
              "  {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.001, 'loss': 'log', 'penalty': 'l1'},\n",
              "  {'alpha': 0.001, 'loss': 'log', 'penalty': 'l2'},\n",
              "  {'alpha': 0.001, 'loss': 'log', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
              "  {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
              "  {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'elasticnet'}],\n",
              " 'rank_test_score': array([27, 13, 14, 26, 24, 25, 10,  4,  5, 19, 12,  7, 17, 22, 23, 20,  1,\n",
              "         2, 16,  3,  6, 11,  8,  9, 21, 18, 15], dtype=int32),\n",
              " 'split0_test_score': array([0.42933333, 0.77666667, 0.78733333, 0.918     , 0.67133333,\n",
              "        0.73066667, 0.92933333, 0.81333333, 0.80266667, 0.78      ,\n",
              "        0.772     , 0.78866667, 0.88      , 0.696     , 0.74333333,\n",
              "        0.75733333, 0.784     , 0.81466667, 0.73533333, 0.76733333,\n",
              "        0.75333333, 0.71333333, 0.78733333, 0.788     , 0.72733333,\n",
              "        0.72733333, 0.75933333]),\n",
              " 'split0_train_score': array([0.67791667, 0.91008333, 0.90416667, 0.83291667, 0.89641667,\n",
              "        0.88425   , 0.94366667, 0.9615    , 0.95475   , 0.90891667,\n",
              "        0.92908333, 0.91775   , 0.86858333, 0.90525   , 0.90691667,\n",
              "        0.94133333, 0.96775   , 0.96633333, 0.986     , 0.97191667,\n",
              "        0.97283333, 0.98716667, 0.97075   , 0.97525   , 0.98333333,\n",
              "        0.98541667, 0.98833333]),\n",
              " 'split1_test_score': array([0.56866667, 0.704     , 0.71533333, 0.66066667, 0.666     ,\n",
              "        0.66533333, 0.70533333, 0.77466667, 0.78      , 0.66266667,\n",
              "        0.74866667, 0.762     , 0.69066667, 0.682     , 0.67666667,\n",
              "        0.88333333, 0.85333333, 0.814     , 0.75266667, 0.82      ,\n",
              "        0.80466667, 0.788     , 0.78533333, 0.79533333, 0.75      ,\n",
              "        0.78866667, 0.88066667]),\n",
              " 'split1_train_score': array([0.78558333, 0.91516667, 0.90691667, 0.85883333, 0.87516667,\n",
              "        0.86816667, 0.93508333, 0.96008333, 0.94616667, 0.88458333,\n",
              "        0.93566667, 0.93033333, 0.88025   , 0.8905    , 0.8895    ,\n",
              "        0.97391667, 0.9685    , 0.96833333, 0.988     , 0.9755    ,\n",
              "        0.97691667, 0.98733333, 0.97325   , 0.97391667, 0.99066667,\n",
              "        0.98316667, 0.99008333]),\n",
              " 'split2_test_score': array([0.558     , 0.792     , 0.78866667, 0.69333333, 0.78333333,\n",
              "        0.77933333, 0.78533333, 0.83533333, 0.85266667, 0.786     ,\n",
              "        0.80866667, 0.806     , 0.762     , 0.78666667, 0.78666667,\n",
              "        0.91066667, 0.92733333, 0.92066667, 0.93666667, 0.93666667,\n",
              "        0.93666667, 0.93666667, 0.93666667, 0.93666667, 0.99333333,\n",
              "        0.93666667, 0.93666667]),\n",
              " 'split2_train_score': array([0.72308333, 0.9225    , 0.91825   , 0.86525   , 0.8875    ,\n",
              "        0.88325   , 0.916     , 0.95216667, 0.95075   , 0.91325   ,\n",
              "        0.933     , 0.9295    , 0.91308333, 0.9085    , 0.913     ,\n",
              "        0.95566667, 0.96075   , 0.96233333, 0.97191667, 0.96716667,\n",
              "        0.96941667, 0.97116667, 0.961     , 0.96016667, 0.98058333,\n",
              "        0.96675   , 0.97358333]),\n",
              " 'split3_test_score': array([0.38466667, 0.89533333, 0.832     , 0.634     , 0.782     ,\n",
              "        0.73133333, 0.88866667, 0.906     , 0.86466667, 0.70333333,\n",
              "        0.89066667, 0.88666667, 0.624     , 0.79733333, 0.74333333,\n",
              "        0.896     , 0.972     , 0.99533333, 0.732     , 0.76266667,\n",
              "        0.66933333, 0.732     , 0.73133333, 0.732     , 0.73266667,\n",
              "        0.66666667, 0.732     ]),\n",
              " 'split3_train_score': array([0.62333333, 0.90175   , 0.88908333, 0.8625    , 0.87841667,\n",
              "        0.87333333, 0.92941667, 0.95825   , 0.94683333, 0.8835    ,\n",
              "        0.924     , 0.91975   , 0.87333333, 0.89575   , 0.89925   ,\n",
              "        0.95366667, 0.96391667, 0.96341667, 0.97958333, 0.96825   ,\n",
              "        0.96958333, 0.97858333, 0.96425   , 0.96491667, 0.97516667,\n",
              "        0.9745    , 0.97475   ]),\n",
              " 'split4_test_score': array([0.758     , 0.95133333, 0.95133333, 0.94733333, 0.966     ,\n",
              "        0.966     , 0.98333333, 0.98733333, 0.98933333, 0.978     ,\n",
              "        0.95066667, 0.95      , 0.99866667, 0.96666667, 0.966     ,\n",
              "        1.        , 0.99533333, 0.94466667, 0.98933333, 1.        ,\n",
              "        1.        , 0.99866667, 0.99933333, 0.99866667, 0.98333333,\n",
              "        0.994     , 0.98933333]),\n",
              " 'split4_train_score': array([0.67775   , 0.90775   , 0.89725   , 0.8305    , 0.8735    ,\n",
              "        0.865     , 0.914     , 0.95516667, 0.95991667, 0.90325   ,\n",
              "        0.93441667, 0.92375   , 0.87266667, 0.89033333, 0.89475   ,\n",
              "        0.97258333, 0.96266667, 0.96066667, 0.97258333, 0.96841667,\n",
              "        0.96841667, 0.979     , 0.96408333, 0.96566667, 0.9795    ,\n",
              "        0.97691667, 0.97583333]),\n",
              " 'split5_test_score': array([0.674     , 0.878     , 0.878     , 0.818     , 0.908     ,\n",
              "        0.904     , 0.87933333, 0.99133333, 0.922     , 0.83533333,\n",
              "        0.89533333, 0.90066667, 0.894     , 0.90866667, 0.908     ,\n",
              "        0.92533333, 0.99666667, 0.97533333, 0.98533333, 0.99066667,\n",
              "        0.99466667, 0.99466667, 0.99866667, 0.99866667, 0.97866667,\n",
              "        0.992     , 0.994     ]),\n",
              " 'split5_train_score': array([0.62458333, 0.90775   , 0.89858333, 0.84833333, 0.87975   ,\n",
              "        0.87008333, 0.90241667, 0.9485    , 0.9525    , 0.87366667,\n",
              "        0.922     , 0.91983333, 0.88141667, 0.89341667, 0.89241667,\n",
              "        0.937     , 0.9635    , 0.96325   , 0.98408333, 0.968     ,\n",
              "        0.96891667, 0.97741667, 0.96575   , 0.966     , 0.98116667,\n",
              "        0.97691667, 0.97566667]),\n",
              " 'split6_test_score': array([0.40066667, 0.96666667, 0.97666667, 0.75466667, 0.966     ,\n",
              "        0.966     , 0.96666667, 0.96866667, 0.96933333, 0.96333333,\n",
              "        0.96666667, 0.96666667, 0.966     , 0.966     , 0.966     ,\n",
              "        0.6       , 0.97933333, 0.96666667, 0.96533333, 0.988     ,\n",
              "        0.99      , 0.972     , 0.99      , 0.99      , 0.66666667,\n",
              "        0.98666667, 0.98533333]),\n",
              " 'split6_train_score': array([0.65983333, 0.9       , 0.89475   , 0.81083333, 0.86583333,\n",
              "        0.85408333, 0.92725   , 0.96083333, 0.95308333, 0.88125   ,\n",
              "        0.9315    , 0.91183333, 0.84383333, 0.88591667, 0.8885    ,\n",
              "        0.96816667, 0.96258333, 0.96608333, 0.97325   , 0.96866667,\n",
              "        0.96891667, 0.97825   , 0.96541667, 0.96575   , 0.97925   ,\n",
              "        0.97308333, 0.97825   ]),\n",
              " 'split7_test_score': array([0.598     , 0.83533333, 0.84466667, 0.676     , 0.86533333,\n",
              "        0.85933333, 0.85466667, 0.84733333, 0.836     , 0.766     ,\n",
              "        0.83266667, 0.818     , 0.80133333, 0.858     , 0.866     ,\n",
              "        0.84333333, 0.84866667, 0.846     , 0.832     , 0.844     ,\n",
              "        0.84133333, 0.83066667, 0.84333333, 0.84266667, 0.83133333,\n",
              "        0.838     , 0.83866667]),\n",
              " 'split7_train_score': array([0.67725   , 0.92116667, 0.918     , 0.85675   , 0.895     ,\n",
              "        0.88791667, 0.92166667, 0.97233333, 0.96766667, 0.91375   ,\n",
              "        0.94616667, 0.93983333, 0.89716667, 0.90675   , 0.908     ,\n",
              "        0.95625   , 0.975     , 0.97775   , 0.98733333, 0.98266667,\n",
              "        0.98175   , 0.98516667, 0.97825   , 0.97875   , 0.98275   ,\n",
              "        0.97741667, 0.98075   ]),\n",
              " 'split8_test_score': array([0.63866667, 0.912     , 0.932     , 0.96933333, 0.69933333,\n",
              "        0.70066667, 0.78866667, 0.80933333, 0.91      , 0.93      ,\n",
              "        0.902     , 0.93066667, 0.95866667, 0.69866667, 0.69933333,\n",
              "        0.58133333, 0.85933333, 0.90133333, 0.70266667, 0.82466667,\n",
              "        0.838     , 0.80666667, 0.73266667, 0.722     , 0.724     ,\n",
              "        0.55533333, 0.56466667]),\n",
              " 'split8_train_score': array([0.5535    , 0.90775   , 0.90633333, 0.83658333, 0.90483333,\n",
              "        0.90658333, 0.94366667, 0.96141667, 0.96116667, 0.90683333,\n",
              "        0.93316667, 0.92591667, 0.88008333, 0.90783333, 0.90683333,\n",
              "        0.95833333, 0.96975   , 0.968     , 0.98241667, 0.97641667,\n",
              "        0.97941667, 0.98766667, 0.97425   , 0.98041667, 0.98525   ,\n",
              "        0.98408333, 0.98491667]),\n",
              " 'std_fit_time': array([0.01648442, 0.00167275, 0.0142391 , 0.00584238, 0.00329507,\n",
              "        0.00286704, 0.05333388, 0.00606102, 0.0133775 , 0.01639302,\n",
              "        0.00230266, 0.00370393, 0.00584012, 0.00247253, 0.00316202,\n",
              "        0.05030496, 0.00811797, 0.0189113 , 0.01570726, 0.00816794,\n",
              "        0.00600025, 0.02462502, 0.01208314, 0.00887586, 0.13913352,\n",
              "        0.00863937, 0.05041865]),\n",
              " 'std_score_time': array([1.04895190e-04, 2.06284085e-05, 5.68145910e-05, 2.44939199e-05,\n",
              "        1.22340482e-04, 2.32792935e-05, 3.21446078e-05, 2.28731242e-05,\n",
              "        1.17002069e-04, 1.06122177e-04, 3.29944524e-04, 4.31317465e-05,\n",
              "        2.47092298e-05, 2.10704892e-04, 2.13380641e-05, 2.57084021e-05,\n",
              "        3.34970535e-05, 8.48649584e-05, 5.31896123e-05, 5.63384043e-05,\n",
              "        2.82583854e-05, 2.36327218e-05, 2.92602862e-05, 6.99913444e-05,\n",
              "        1.36496548e-05, 3.10275000e-05, 5.52204413e-05]),\n",
              " 'std_test_score': array([0.12157038, 0.08193329, 0.08141041, 0.12408245, 0.11304427,\n",
              "        0.10864255, 0.08629118, 0.07890158, 0.06789858, 0.10636041,\n",
              "        0.07225682, 0.07123885, 0.12299879, 0.10690344, 0.10561773,\n",
              "        0.1379624 , 0.0738507 , 0.06543714, 0.11405671, 0.09184474,\n",
              "        0.11119464, 0.1066931 , 0.10793907, 0.10846084, 0.12286449,\n",
              "        0.15035829, 0.1376388 ]),\n",
              " 'std_train_score': array([0.06163216, 0.00737256, 0.0093999 , 0.01716136, 0.01196743,\n",
              "        0.01450841, 0.01307601, 0.00638176, 0.00662399, 0.01471787,\n",
              "        0.00662475, 0.00779324, 0.01800513, 0.00831739, 0.00853483,\n",
              "        0.01207696, 0.00428555, 0.00475194, 0.00614102, 0.00497556,\n",
              "        0.00485221, 0.00543693, 0.00544274, 0.00669386, 0.00409891,\n",
              "        0.00560575, 0.00580488])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWxUUHr3gHF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59380c04-ed8d-4fb3-deb6-e8ef9173aa98"
      },
      "source": [
        "#Best parameters obtained from grid search\n",
        "gs.best_params_"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.05, 'loss': 'modified_huber', 'penalty': 'l2'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49v8P0MCgKBy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4e6743e-eddb-4c61-e1cc-03678667e3f6"
      },
      "source": [
        "#Best score\n",
        "gs.best_score_"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9128888888888889"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KOUBGFYgL_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4c7917be-78aa-44cc-daad-bdfe95834a92"
      },
      "source": [
        "#Training the classifier with best parameter\n",
        "bestclf = SGDClassifier(alpha= 0.05, loss= 'modified_huber', penalty= 'l2')\n",
        "bestclf.fit(X_train, y_train)\n",
        "tr_p = bestclf.predict(X_train)\n",
        "print(accuracy_score(y_train, tr_p))\n",
        "confusion_matrix(y_train, tr_p)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9660740740740741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2770,    0,   10,    0,    4],\n",
              "       [   5, 2433,    7,   60,   77],\n",
              "       [   9,    0, 2483,  134,   23],\n",
              "       [   1,   20,   19, 2429,    7],\n",
              "       [   1,   58,    3,   20, 2927]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTxun8algO3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "98614d39-1a12-4680-df27-f7db64e57911"
      },
      "source": [
        "#Running the model on the test set\n",
        "predictions = bestclf.predict(X_test)\n",
        "print(accuracy_score(y_test, predictions))\n",
        "confusion_matrix(y_test, predictions)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8776245319683398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4298,   48,   43,    0,   77],\n",
              "       [  39, 4198,   60,  105,    0],\n",
              "       [ 954,    1, 3729,    5,   90],\n",
              "       [   0,  777,   17, 2987,  133],\n",
              "       [  19,   18,   10,  186, 3305]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cqa8qcRhIhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import RFE, RFECV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHovuA-pmANv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading expanded dataset\n",
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/mpr/linearTrainexpanded.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/mpr/linearTestexpanded.csv')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBIhEe4umCXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train.iloc[:, 1:60]\n",
        "y_train = train.iloc[:,60]\n",
        "X_test = test.iloc[:, 1:60]\n",
        "y_test = test.iloc[:, 60]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNtEN6Q1mGhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalizing the data\n",
        "from sklearn import preprocessing\n",
        "scalar = preprocessing.StandardScaler()\n",
        "scalar.fit(X_train)\n",
        "X_train = scalar.transform(X_train)\n",
        "X_test = scalar.transform(X_test)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "X_test = pd.DataFrame(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOJh5zqbmIo-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "ca36c6e5-8cc5-4105-cd61-71c2e431e83d"
      },
      "source": [
        "kf = KFold(n_splits=9, random_state=None, shuffle=False)\n",
        "params = {'loss':['hinge', 'log', 'modified_huber'], 'penalty':['l1', 'l2', 'elasticnet'], 'alpha': [0.1, 0.05, 0.001]}\n",
        "clf = SGDClassifier()\n",
        "gs = GridSearchCV(clf, cv=kf, param_grid=params, return_train_score=True)\n",
        "\n",
        "gs.fit(X_train, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=9, random_state=None, shuffle=False),\n",
              "             error_score=nan,\n",
              "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
              "                                     class_weight=None, early_stopping=False,\n",
              "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "                                     l1_ratio=0.15, learning_rate='optimal',\n",
              "                                     loss='hinge', max_iter=1000,\n",
              "                                     n_iter_no_change=5, n_jobs=None,\n",
              "                                     penalty='l2', power_t=0.5,\n",
              "                                     random_state=None, shuffle=True, tol=0.001,\n",
              "                                     validation_fraction=0.1, verbose=0,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'alpha': [0.1, 0.05, 0.001],\n",
              "                         'loss': ['hinge', 'log', 'modified_huber'],\n",
              "                         'penalty': ['l1', 'l2', 'elasticnet']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkXZM0Q4mKvP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f70fac9-9d60-4b46-db37-baa8f36f612c"
      },
      "source": [
        "#Visualizing results of grid search\n",
        "gs.cv_results_"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.33609287, 0.1236736 , 0.24461044, 0.42760187, 0.1951925 ,\n",
              "        0.36277946, 1.88350662, 0.29358588, 0.7139061 , 0.27381849,\n",
              "        0.12466023, 0.24160147, 0.3999868 , 0.19116092, 0.35051073,\n",
              "        1.80638088, 0.38242483, 0.94280876, 0.57371407, 0.23757633,\n",
              "        0.50755572, 0.9093944 , 0.38227654, 0.64989816, 3.37193113,\n",
              "        1.05523242, 2.64132531]),\n",
              " 'mean_score_time': array([0.00216757, 0.00209374, 0.00217255, 0.00231157, 0.00208386,\n",
              "        0.00213464, 0.00239306, 0.00215358, 0.00214913, 0.0021099 ,\n",
              "        0.00215414, 0.00212349, 0.00211403, 0.00209652, 0.00214338,\n",
              "        0.0021454 , 0.00210685, 0.00214966, 0.00212926, 0.00210277,\n",
              "        0.00212222, 0.00210187, 0.00214805, 0.00211162, 0.0022001 ,\n",
              "        0.00210121, 0.00211785]),\n",
              " 'mean_test_score': array([0.68881481, 0.81688889, 0.82088889, 0.79822222, 0.79622222,\n",
              "        0.80318519, 0.78066667, 0.83014815, 0.83177778, 0.84896296,\n",
              "        0.83377778, 0.82881481, 0.83296296, 0.80725926, 0.80392593,\n",
              "        0.82748148, 0.80681481, 0.81177778, 0.86962963, 0.84985185,\n",
              "        0.84444444, 0.85711111, 0.86148148, 0.86525926, 0.87562963,\n",
              "        0.79      , 0.79577778]),\n",
              " 'mean_train_score': array([0.77471296, 0.94506481, 0.93212037, 0.8542037 , 0.91243519,\n",
              "        0.90553704, 0.90825   , 0.96578704, 0.96711111, 0.92096296,\n",
              "        0.96011111, 0.95464815, 0.90705556, 0.93640741, 0.92652778,\n",
              "        0.95583333, 0.9712963 , 0.97033333, 0.98772222, 0.98909259,\n",
              "        0.98874074, 0.98739815, 0.98617593, 0.98601852, 0.98847222,\n",
              "        0.98608333, 0.98653704]),\n",
              " 'param_alpha': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.05,\n",
              "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.001,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_loss': masked_array(data=['hinge', 'hinge', 'hinge', 'log', 'log', 'log',\n",
              "                    'modified_huber', 'modified_huber', 'modified_huber',\n",
              "                    'hinge', 'hinge', 'hinge', 'log', 'log', 'log',\n",
              "                    'modified_huber', 'modified_huber', 'modified_huber',\n",
              "                    'hinge', 'hinge', 'hinge', 'log', 'log', 'log',\n",
              "                    'modified_huber', 'modified_huber', 'modified_huber'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_penalty': masked_array(data=['l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l1'},\n",
              "  {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l2'},\n",
              "  {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.1, 'loss': 'log', 'penalty': 'l1'},\n",
              "  {'alpha': 0.1, 'loss': 'log', 'penalty': 'l2'},\n",
              "  {'alpha': 0.1, 'loss': 'log', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
              "  {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
              "  {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.05, 'loss': 'hinge', 'penalty': 'l1'},\n",
              "  {'alpha': 0.05, 'loss': 'hinge', 'penalty': 'l2'},\n",
              "  {'alpha': 0.05, 'loss': 'hinge', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.05, 'loss': 'log', 'penalty': 'l1'},\n",
              "  {'alpha': 0.05, 'loss': 'log', 'penalty': 'l2'},\n",
              "  {'alpha': 0.05, 'loss': 'log', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.05, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
              "  {'alpha': 0.05, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
              "  {'alpha': 0.05, 'loss': 'modified_huber', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l1'},\n",
              "  {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l2'},\n",
              "  {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.001, 'loss': 'log', 'penalty': 'l1'},\n",
              "  {'alpha': 0.001, 'loss': 'log', 'penalty': 'l2'},\n",
              "  {'alpha': 0.001, 'loss': 'log', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
              "  {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
              "  {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'elasticnet'}],\n",
              " 'rank_test_score': array([27, 16, 15, 22, 23, 21, 26, 12, 11,  7,  9, 13, 10, 18, 20, 14, 19,\n",
              "        17,  2,  6,  8,  5,  4,  3,  1, 25, 24], dtype=int32),\n",
              " 'split0_test_score': array([0.65266667, 0.78066667, 0.80666667, 0.89533333, 0.68266667,\n",
              "        0.71133333, 0.734     , 0.75133333, 0.75266667, 0.79266667,\n",
              "        0.76866667, 0.76333333, 0.80133333, 0.732     , 0.73266667,\n",
              "        0.766     , 0.75333333, 0.75      , 0.744     , 0.75333333,\n",
              "        0.74333333, 0.74933333, 0.764     , 0.766     , 0.75066667,\n",
              "        0.70066667, 0.702     ]),\n",
              " 'split0_train_score': array([0.81425   , 0.95241667, 0.93816667, 0.85058333, 0.918     ,\n",
              "        0.905     , 0.91483333, 0.97191667, 0.96891667, 0.93258333,\n",
              "        0.96341667, 0.96141667, 0.89091667, 0.93783333, 0.93991667,\n",
              "        0.95741667, 0.97025   , 0.9715    , 0.9895    , 0.99083333,\n",
              "        0.99166667, 0.99033333, 0.98983333, 0.98933333, 0.99091667,\n",
              "        0.98825   , 0.98808333]),\n",
              " 'split1_test_score': array([0.68      , 0.78066667, 0.766     , 0.678     , 0.734     ,\n",
              "        0.718     , 0.85866667, 0.88466667, 0.88666667, 0.75733333,\n",
              "        0.81      , 0.79933333, 0.714     , 0.75266667, 0.756     ,\n",
              "        0.796     , 0.90866667, 0.914     , 0.79533333, 0.91266667,\n",
              "        0.91266667, 0.802     , 0.91266667, 0.912     , 0.808     ,\n",
              "        0.91866667, 0.92133333]),\n",
              " 'split1_train_score': array([0.86766667, 0.94625   , 0.93525   , 0.8625    , 0.90633333,\n",
              "        0.90216667, 0.93983333, 0.96283333, 0.96733333, 0.92516667,\n",
              "        0.96183333, 0.9545    , 0.91083333, 0.933     , 0.92175   ,\n",
              "        0.94908333, 0.9755    , 0.98008333, 0.99116667, 0.99066667,\n",
              "        0.99075   , 0.98875   , 0.9895    , 0.98833333, 0.991     ,\n",
              "        0.98808333, 0.98783333]),\n",
              " 'split2_test_score': array([0.66733333, 0.81333333, 0.81133333, 0.72466667, 0.784     ,\n",
              "        0.76866667, 0.898     , 0.95933333, 0.95066667, 0.79066667,\n",
              "        0.872     , 0.83066667, 0.76      , 0.82266667, 0.79333333,\n",
              "        0.884     , 0.992     , 0.99333333, 0.93333333, 0.996     ,\n",
              "        0.996     , 0.90866667, 0.996     , 0.99666667, 0.97466667,\n",
              "        1.        , 1.        ]),\n",
              " 'split2_train_score': array([0.83966667, 0.93491667, 0.93208333, 0.88766667, 0.91233333,\n",
              "        0.90858333, 0.89291667, 0.96741667, 0.96466667, 0.91966667,\n",
              "        0.9515    , 0.94183333, 0.9035    , 0.93241667, 0.92      ,\n",
              "        0.93808333, 0.97241667, 0.97175   , 0.98483333, 0.98816667,\n",
              "        0.98833333, 0.98458333, 0.98366667, 0.98266667, 0.987     ,\n",
              "        0.98641667, 0.98725   ]),\n",
              " 'split3_test_score': array([0.582     , 0.81866667, 0.814     , 0.61333333, 0.872     ,\n",
              "        0.85066667, 0.692     , 0.806     , 0.88333333, 0.92733333,\n",
              "        0.82733333, 0.85266667, 0.83466667, 0.87133333, 0.83133333,\n",
              "        0.95733333, 0.70533333, 0.714     , 0.88466667, 0.81066667,\n",
              "        0.81666667, 0.76466667, 0.80733333, 0.83533333, 0.856     ,\n",
              "        0.746     , 0.738     ]),\n",
              " 'split3_train_score': array([0.71758333, 0.94416667, 0.92883333, 0.865     , 0.9175    ,\n",
              "        0.90433333, 0.894     , 0.96008333, 0.969     , 0.91466667,\n",
              "        0.95758333, 0.95216667, 0.91166667, 0.93608333, 0.92766667,\n",
              "        0.96483333, 0.96808333, 0.96625   , 0.98841667, 0.98916667,\n",
              "        0.9895    , 0.98825   , 0.98566667, 0.98641667, 0.98683333,\n",
              "        0.98575   , 0.987     ]),\n",
              " 'split4_test_score': array([0.64933333, 0.95733333, 0.97066667, 0.98133333, 0.962     ,\n",
              "        0.97066667, 0.86733333, 0.93066667, 0.81866667, 0.97933333,\n",
              "        0.98533333, 0.978     , 0.97866667, 0.964     , 0.96866667,\n",
              "        0.94333333, 0.83133333, 0.82933333, 0.97866667, 0.82466667,\n",
              "        0.822     , 0.99866667, 0.85133333, 0.84933333, 0.996     ,\n",
              "        0.80266667, 0.79466667]),\n",
              " 'split4_train_score': array([0.71041667, 0.935     , 0.92766667, 0.84908333, 0.907     ,\n",
              "        0.90008333, 0.87916667, 0.962     , 0.96483333, 0.91158333,\n",
              "        0.95833333, 0.94941667, 0.89225   , 0.93508333, 0.91991667,\n",
              "        0.95991667, 0.97433333, 0.973     , 0.98341667, 0.98866667,\n",
              "        0.98725   , 0.98383333, 0.9845    , 0.985     , 0.98708333,\n",
              "        0.98633333, 0.98566667]),\n",
              " 'split5_test_score': array([0.828     , 0.88666667, 0.88533333, 0.85466667, 0.86066667,\n",
              "        0.87333333, 0.86533333, 0.91933333, 0.88933333, 0.88333333,\n",
              "        0.936     , 0.89266667, 0.884     , 0.876     , 0.87466667,\n",
              "        0.918     , 0.90933333, 0.92066667, 0.946     , 0.92733333,\n",
              "        0.92866667, 0.92733333, 0.924     , 0.92333333, 0.958     ,\n",
              "        0.93266667, 0.92866667]),\n",
              " 'split5_train_score': array([0.7525    , 0.94708333, 0.9325    , 0.85341667, 0.90641667,\n",
              "        0.90191667, 0.90916667, 0.96308333, 0.9655    , 0.9255    ,\n",
              "        0.95941667, 0.95208333, 0.93566667, 0.9345    , 0.924     ,\n",
              "        0.95916667, 0.96675   , 0.96116667, 0.9875    , 0.98916667,\n",
              "        0.98916667, 0.98516667, 0.98441667, 0.98425   , 0.9865    ,\n",
              "        0.98675   , 0.987     ]),\n",
              " 'split6_test_score': array([0.57866667, 0.602     , 0.61333333, 0.66866667, 0.58933333,\n",
              "        0.59933333, 0.72      , 0.61733333, 0.638     , 0.74266667,\n",
              "        0.63133333, 0.65333333, 0.77866667, 0.568     , 0.598     ,\n",
              "        0.78266667, 0.598     , 0.54266667, 0.966     , 0.86066667,\n",
              "        0.78666667, 0.98133333, 0.88666667, 0.89733333, 0.95533333,\n",
              "        0.718     , 0.76866667]),\n",
              " 'split6_train_score': array([0.7725    , 0.93983333, 0.92516667, 0.8365    , 0.90916667,\n",
              "        0.8985    , 0.91975   , 0.96375   , 0.96433333, 0.90666667,\n",
              "        0.95458333, 0.95116667, 0.88541667, 0.93291667, 0.921     ,\n",
              "        0.94525   , 0.96583333, 0.96016667, 0.98591667, 0.98883333,\n",
              "        0.98658333, 0.98816667, 0.98366667, 0.984     , 0.98775   ,\n",
              "        0.98475   , 0.9855    ]),\n",
              " 'split7_test_score': array([0.61866667, 0.88333333, 0.87333333, 0.96866667, 0.85733333,\n",
              "        0.88333333, 0.88266667, 0.824     , 0.846     , 0.874     ,\n",
              "        0.878     , 0.88      , 0.84      , 0.87933333, 0.87866667,\n",
              "        0.88466667, 0.814     , 0.858     , 0.85266667, 0.816     ,\n",
              "        0.844     , 0.85466667, 0.86333333, 0.85333333, 0.86066667,\n",
              "        0.69866667, 0.70333333]),\n",
              " 'split7_train_score': array([0.78708333, 0.95716667, 0.92941667, 0.84525   , 0.90916667,\n",
              "        0.91325   , 0.91941667, 0.9705    , 0.972     , 0.91458333,\n",
              "        0.96933333, 0.96625   , 0.92925   , 0.94033333, 0.93108333,\n",
              "        0.963     , 0.97525   , 0.97633333, 0.98891667, 0.98841667,\n",
              "        0.98783333, 0.989     , 0.98716667, 0.98625   , 0.98833333,\n",
              "        0.98333333, 0.98375   ]),\n",
              " 'split8_test_score': array([0.94266667, 0.82933333, 0.84733333, 0.79933333, 0.824     ,\n",
              "        0.85333333, 0.508     , 0.77866667, 0.82066667, 0.89333333,\n",
              "        0.79533333, 0.80933333, 0.90533333, 0.79933333, 0.802     ,\n",
              "        0.51533333, 0.74933333, 0.784     , 0.726     , 0.74733333,\n",
              "        0.75      , 0.72733333, 0.748     , 0.754     , 0.72133333,\n",
              "        0.59266667, 0.60533333]),\n",
              " 'split8_train_score': array([0.71075   , 0.94875   , 0.94      , 0.83783333, 0.926     ,\n",
              "        0.916     , 0.90516667, 0.9705    , 0.96741667, 0.93825   ,\n",
              "        0.965     , 0.963     , 0.904     , 0.9455    , 0.93341667,\n",
              "        0.96575   , 0.97325   , 0.97275   , 0.98983333, 0.98791667,\n",
              "        0.98758333, 0.9885    , 0.98716667, 0.98791667, 0.99083333,\n",
              "        0.98508333, 0.98675   ]),\n",
              " 'std_fit_time': array([0.08954727, 0.00423067, 0.02085439, 0.04606681, 0.01029276,\n",
              "        0.00919378, 0.43677125, 0.03579551, 0.11636267, 0.03100116,\n",
              "        0.00989913, 0.02717669, 0.02500533, 0.00609261, 0.01289704,\n",
              "        0.32885993, 0.06160914, 0.17847989, 0.09197033, 0.01622457,\n",
              "        0.05405513, 0.12184004, 0.03597537, 0.06827254, 0.60400759,\n",
              "        0.10616978, 0.27311234]),\n",
              " 'std_score_time': array([9.66584134e-05, 5.76292528e-05, 7.33828477e-05, 4.84794972e-04,\n",
              "        2.62633453e-05, 9.04634364e-05, 5.37385896e-04, 5.87202559e-05,\n",
              "        3.31508428e-05, 2.71360219e-05, 9.54709845e-05, 2.70605055e-05,\n",
              "        4.30539689e-05, 4.27541991e-05, 7.08956709e-05, 3.94544308e-05,\n",
              "        3.00883822e-05, 5.94963574e-05, 3.17252586e-05, 3.32268794e-05,\n",
              "        1.90044112e-05, 2.58640987e-05, 4.87436419e-05, 3.00442682e-05,\n",
              "        9.37587403e-05, 5.47861991e-05, 3.89438817e-05]),\n",
              " 'std_test_score': array([0.11337288, 0.09308326, 0.09217696, 0.12738006, 0.10625058,\n",
              "        0.10677299, 0.1215647 , 0.10137513, 0.08655377, 0.07686776,\n",
              "        0.09669144, 0.08554128, 0.07641156, 0.10790048, 0.09909439,\n",
              "        0.12873622, 0.11347868, 0.12661519, 0.0903776 , 0.07786521,\n",
              "        0.08060451, 0.09609358, 0.07503861, 0.07255373, 0.09547599,\n",
              "        0.12629419, 0.12147895]),\n",
              " 'std_train_score': array([0.05432716, 0.00708696, 0.00465344, 0.014932  , 0.0063683 ,\n",
              "        0.00561456, 0.01697106, 0.00410569, 0.00241171, 0.00969831,\n",
              "        0.00513791, 0.00720058, 0.01604373, 0.00401856, 0.0066237 ,\n",
              "        0.0090285 , 0.00348854, 0.00624895, 0.00239405, 0.00096979,\n",
              "        0.00158331, 0.00213827, 0.00223967, 0.00209857, 0.00179978,\n",
              "        0.00148189, 0.00127603])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcRGJ9BsnFUZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "90faf1ea-ef37-4db4-8e7d-03b7b6b1db18"
      },
      "source": [
        "#Best estimator obtained by grid search\n",
        "gs.best_estimator_"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
              "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTyIrN-YnI5P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c40cfe4f-8246-4103-f9d1-8551231e57ff"
      },
      "source": [
        "#Best parameters\n",
        "gs.best_params_"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l1'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ8SwFljnKc0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54bf93a1-9700-4991-b48e-6e755143d618"
      },
      "source": [
        "#Best score\n",
        "gs.best_score_"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8756296296296296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySYB6r-inMKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "79cfa880-e4da-4769-c264-2cc6255746f2"
      },
      "source": [
        "#Training the model with best parameters\n",
        "bestclf = SGDClassifier(alpha= 0.001, loss= 'modified_huber', penalty= 'l1')\n",
        "bestclf.fit(X_train, y_train)\n",
        "tr_p = bestclf.predict(X_train)\n",
        "print(accuracy_score(y_train, tr_p))\n",
        "confusion_matrix(y_train, tr_p)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9879259259259259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2781,    0,    0,    1,    2],\n",
              "       [   3, 2510,    7,   22,   40],\n",
              "       [  12,    0, 2622,   13,    2],\n",
              "       [   1,    3,   25, 2446,    1],\n",
              "       [   0,   22,    5,    4, 2978]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV-qh6QAnVkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "526c4db7-9b0d-4874-f271-1e7e1870381e"
      },
      "source": [
        "#Running the model on the test set\n",
        "predictions = bestclf.predict(X_test)\n",
        "print(accuracy_score(y_test, predictions))\n",
        "confusion_matrix(y_test, predictions)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8280961182994455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4264,   44,   49,    0,  109],\n",
              "       [   0, 1905,   31,  159, 2307],\n",
              "       [  36,    0, 4276,  467,    0],\n",
              "       [   0,    1,  217, 3693,    3],\n",
              "       [   0,   48,    2,  154, 3334]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liRGGtnfhtFS",
        "colab_type": "text"
      },
      "source": [
        "Implementing SGD Classifier on optimal features selected from the expanded dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y14pHZgtnaFc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "86e41580-3ed3-48d0-d7ae-dce3a099a096"
      },
      "source": [
        "kf = KFold(n_splits=9, random_state=None, shuffle=False)\n",
        "model = SGDClassifier()\n",
        "rfecv = RFECV(estimator=model, cv=kf,scoring='accuracy')\n",
        "rfecv.fit(X_train, y_train)\n",
        "\n",
        "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal number of features : 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k_JRH2Nngdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selected = rfecv.support_"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tLtDfgPoMvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num = 0\n",
        "todelete = []\n",
        "for i in selected:\n",
        "  if i ==False:\n",
        "    todelete.append(num)\n",
        "    num += 1"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WUteQpxoQIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_selected = X_train.drop(X_train.columns[todelete], axis=1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgLDGQkGoSV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_selected = X_test.drop(X_test.columns[todelete], axis=1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXlnFCxgoWn2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "1e2a5c2b-a942-4020-a688-231ecce7c1ea"
      },
      "source": [
        "kf = KFold(n_splits=9, random_state=None, shuffle=False)\n",
        "params = {'loss':['hinge', 'log', 'modified_huber'], 'penalty':['l1', 'l2', 'elasticnet'], 'alpha': [0.1, 0.05, 0.001]}\n",
        "clf = SGDClassifier()\n",
        "gs = GridSearchCV(clf, cv=kf, param_grid=params, return_train_score=True)\n",
        "\n",
        "gs.fit(X_train_selected, y_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=9, random_state=None, shuffle=False),\n",
              "             error_score=nan,\n",
              "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
              "                                     class_weight=None, early_stopping=False,\n",
              "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "                                     l1_ratio=0.15, learning_rate='optimal',\n",
              "                                     loss='hinge', max_iter=1000,\n",
              "                                     n_iter_no_change=5, n_jobs=None,\n",
              "                                     penalty='l2', power_t=0.5,\n",
              "                                     random_state=None, shuffle=True, tol=0.001,\n",
              "                                     validation_fraction=0.1, verbose=0,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'alpha': [0.1, 0.05, 0.001],\n",
              "                         'loss': ['hinge', 'log', 'modified_huber'],\n",
              "                         'penalty': ['l1', 'l2', 'elasticnet']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-CmowFzoa5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f790b14c-81d1-4a51-a824-4587d582e87f"
      },
      "source": [
        "#Visualizing the results of grid search\n",
        "gs.cv_results_"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.14614823, 0.08189943, 0.14712172, 0.24246727, 0.14200648,\n",
              "        0.21135306, 0.53987413, 0.1383423 , 0.24635985, 0.15842178,\n",
              "        0.0822325 , 0.14320781, 0.2295529 , 0.14323592, 0.21036185,\n",
              "        0.74682071, 0.16696713, 0.31316262, 0.37770531, 0.15258121,\n",
              "        0.26870656, 0.48036263, 0.21188898, 0.31079761, 2.6169414 ,\n",
              "        0.46771317, 0.95938616]),\n",
              " 'mean_score_time': array([0.00158906, 0.0020562 , 0.00171116, 0.00156591, 0.00153915,\n",
              "        0.00156493, 0.00160321, 0.00153859, 0.00157351, 0.00152021,\n",
              "        0.00206992, 0.00152686, 0.00157287, 0.00154246, 0.0015605 ,\n",
              "        0.00158678, 0.00154376, 0.00155796, 0.00154736, 0.00153732,\n",
              "        0.00155814, 0.00157589, 0.0015924 , 0.00155335, 0.00158683,\n",
              "        0.00155542, 0.00156246]),\n",
              " 'mean_test_score': array([0.58903704, 0.71037037, 0.72814815, 0.74511111, 0.73962963,\n",
              "        0.73925926, 0.69733333, 0.72792593, 0.70822222, 0.756     ,\n",
              "        0.71355556, 0.73562963, 0.77762963, 0.74533333, 0.73518519,\n",
              "        0.71940741, 0.72837037, 0.70762963, 0.73933333, 0.76044444,\n",
              "        0.74896296, 0.75437037, 0.74311111, 0.74851852, 0.75903704,\n",
              "        0.73333333, 0.7262963 ]),\n",
              " 'mean_train_score': array([0.61573148, 0.87081481, 0.862     , 0.80961111, 0.84034259,\n",
              "        0.84069444, 0.89975926, 0.9215463 , 0.92178704, 0.85037037,\n",
              "        0.89735185, 0.89068519, 0.85013889, 0.87088889, 0.86821296,\n",
              "        0.93548148, 0.93673148, 0.93487963, 0.96207407, 0.95037963,\n",
              "        0.95125   , 0.95803704, 0.94409259, 0.94616667, 0.95382407,\n",
              "        0.95371296, 0.95402778]),\n",
              " 'param_alpha': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.05,\n",
              "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.001,\n",
              "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_loss': masked_array(data=['hinge', 'hinge', 'hinge', 'log', 'log', 'log',\n",
              "                    'modified_huber', 'modified_huber', 'modified_huber',\n",
              "                    'hinge', 'hinge', 'hinge', 'log', 'log', 'log',\n",
              "                    'modified_huber', 'modified_huber', 'modified_huber',\n",
              "                    'hinge', 'hinge', 'hinge', 'log', 'log', 'log',\n",
              "                    'modified_huber', 'modified_huber', 'modified_huber'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_penalty': masked_array(data=['l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet', 'l1', 'l2', 'elasticnet',\n",
              "                    'l1', 'l2', 'elasticnet'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l1'},\n",
              "  {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'l2'},\n",
              "  {'alpha': 0.1, 'loss': 'hinge', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.1, 'loss': 'log', 'penalty': 'l1'},\n",
              "  {'alpha': 0.1, 'loss': 'log', 'penalty': 'l2'},\n",
              "  {'alpha': 0.1, 'loss': 'log', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
              "  {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
              "  {'alpha': 0.1, 'loss': 'modified_huber', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.05, 'loss': 'hinge', 'penalty': 'l1'},\n",
              "  {'alpha': 0.05, 'loss': 'hinge', 'penalty': 'l2'},\n",
              "  {'alpha': 0.05, 'loss': 'hinge', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.05, 'loss': 'log', 'penalty': 'l1'},\n",
              "  {'alpha': 0.05, 'loss': 'log', 'penalty': 'l2'},\n",
              "  {'alpha': 0.05, 'loss': 'log', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.05, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
              "  {'alpha': 0.05, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
              "  {'alpha': 0.05, 'loss': 'modified_huber', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l1'},\n",
              "  {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'l2'},\n",
              "  {'alpha': 0.001, 'loss': 'hinge', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.001, 'loss': 'log', 'penalty': 'l1'},\n",
              "  {'alpha': 0.001, 'loss': 'log', 'penalty': 'l2'},\n",
              "  {'alpha': 0.001, 'loss': 'log', 'penalty': 'elasticnet'},\n",
              "  {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l1'},\n",
              "  {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'l2'},\n",
              "  {'alpha': 0.001, 'loss': 'modified_huber', 'penalty': 'elasticnet'}],\n",
              " 'rank_test_score': array([27, 23, 18,  9, 11, 13, 26, 19, 24,  4, 22, 14,  1,  8, 15, 21, 17,\n",
              "        25, 12,  2,  6,  5, 10,  7,  3, 16, 20], dtype=int32),\n",
              " 'split0_test_score': array([0.45133333, 0.646     , 0.64133333, 0.69      , 0.54933333,\n",
              "        0.618     , 0.67066667, 0.754     , 0.72066667, 0.80266667,\n",
              "        0.684     , 0.70266667, 0.80866667, 0.59      , 0.62533333,\n",
              "        0.786     , 0.80533333, 0.78666667, 0.768     , 0.82666667,\n",
              "        0.81933333, 0.75733333, 0.78066667, 0.77733333, 0.734     ,\n",
              "        0.728     , 0.72933333]),\n",
              " 'split0_train_score': array([0.60191667, 0.86533333, 0.8535    , 0.82675   , 0.83225   ,\n",
              "        0.84391667, 0.89258333, 0.91475   , 0.90991667, 0.83091667,\n",
              "        0.88241667, 0.87225   , 0.83075   , 0.86225   , 0.85841667,\n",
              "        0.9195    , 0.93191667, 0.93625   , 0.96566667, 0.94875   ,\n",
              "        0.95133333, 0.96141667, 0.94425   , 0.94325   , 0.9585    ,\n",
              "        0.94775   , 0.95825   ]),\n",
              " 'split1_test_score': array([0.49133333, 0.62466667, 0.61466667, 0.71066667, 0.664     ,\n",
              "        0.618     , 0.88466667, 0.68466667, 0.68933333, 0.54266667,\n",
              "        0.62466667, 0.63266667, 0.73066667, 0.66866667, 0.648     ,\n",
              "        0.86933333, 0.71      , 0.73      , 0.834     , 0.81333333,\n",
              "        0.82866667, 0.91133333, 0.76066667, 0.76333333, 0.852     ,\n",
              "        0.89466667, 0.88733333]),\n",
              " 'split1_train_score': array([0.60891667, 0.88133333, 0.86716667, 0.795     , 0.84175   ,\n",
              "        0.8365    , 0.925     , 0.92633333, 0.91975   , 0.84283333,\n",
              "        0.90433333, 0.89933333, 0.83525   , 0.87275   , 0.86891667,\n",
              "        0.941     , 0.9395    , 0.93366667, 0.96641667, 0.95825   ,\n",
              "        0.95691667, 0.96483333, 0.94875   , 0.94958333, 0.96458333,\n",
              "        0.96533333, 0.96541667]),\n",
              " 'split2_test_score': array([0.51066667, 0.74133333, 0.72666667, 0.808     , 0.77      ,\n",
              "        0.756     , 0.90866667, 0.826     , 0.814     , 0.76066667,\n",
              "        0.75266667, 0.73466667, 0.75333333, 0.76933333, 0.754     ,\n",
              "        0.98533333, 0.85466667, 0.85      , 0.892     , 0.85466667,\n",
              "        0.808     , 0.85333333, 0.82333333, 0.80933333, 0.86933333,\n",
              "        0.84466667, 0.86533333]),\n",
              " 'split2_train_score': array([0.62008333, 0.88108333, 0.874     , 0.79675   , 0.843     ,\n",
              "        0.84683333, 0.89033333, 0.9215    , 0.91608333, 0.85233333,\n",
              "        0.90158333, 0.89716667, 0.84116667, 0.87783333, 0.8705    ,\n",
              "        0.93833333, 0.9345    , 0.93041667, 0.96108333, 0.94608333,\n",
              "        0.94408333, 0.95616667, 0.93908333, 0.94225   , 0.95391667,\n",
              "        0.94841667, 0.94908333]),\n",
              " 'split3_test_score': array([0.45266667, 0.582     , 0.734     , 0.434     , 0.83      ,\n",
              "        0.778     , 0.45      , 0.53933333, 0.52      , 0.66533333,\n",
              "        0.57933333, 0.74666667, 0.532     , 0.84466667, 0.75533333,\n",
              "        0.50333333, 0.45666667, 0.49266667, 0.556     , 0.55333333,\n",
              "        0.588     , 0.652     , 0.514     , 0.554     , 0.66533333,\n",
              "        0.548     , 0.55733333]),\n",
              " 'split3_train_score': array([0.63616667, 0.86433333, 0.84833333, 0.86441667, 0.83875   ,\n",
              "        0.84475   , 0.88541667, 0.91775   , 0.91616667, 0.85691667,\n",
              "        0.8975    , 0.8855    , 0.8655    , 0.86441667, 0.86191667,\n",
              "        0.93508333, 0.93733333, 0.933     , 0.95208333, 0.9455    ,\n",
              "        0.94408333, 0.9505    , 0.94308333, 0.94416667, 0.94883333,\n",
              "        0.95008333, 0.94416667]),\n",
              " 'split4_test_score': array([0.68      , 0.84      , 0.858     , 0.88733333, 0.838     ,\n",
              "        0.856     , 0.89933333, 0.86466667, 0.84133333, 0.90066667,\n",
              "        0.844     , 0.85      , 0.944     , 0.83933333, 0.85466667,\n",
              "        0.808     , 0.85866667, 0.77466667, 0.8       , 0.836     ,\n",
              "        0.84133333, 0.79733333, 0.85866667, 0.88933333, 0.786     ,\n",
              "        0.73866667, 0.69933333]),\n",
              " 'split4_train_score': array([0.59758333, 0.87166667, 0.85758333, 0.80966667, 0.83791667,\n",
              "        0.82266667, 0.87441667, 0.9275    , 0.923     , 0.877     ,\n",
              "        0.89833333, 0.89291667, 0.83458333, 0.86866667, 0.86116667,\n",
              "        0.93608333, 0.936     , 0.93458333, 0.96533333, 0.94866667,\n",
              "        0.94916667, 0.96041667, 0.939     , 0.94316667, 0.95833333,\n",
              "        0.94983333, 0.94883333]),\n",
              " 'split5_test_score': array([0.59066667, 0.83133333, 0.80266667, 0.75333333, 0.838     ,\n",
              "        0.83933333, 0.814     , 0.85066667, 0.84333333, 0.79066667,\n",
              "        0.84533333, 0.83866667, 0.82533333, 0.844     , 0.83933333,\n",
              "        0.82466667, 0.86066667, 0.84733333, 0.84      , 0.83666667,\n",
              "        0.83133333, 0.83466667, 0.84666667, 0.84      , 0.812     ,\n",
              "        0.81066667, 0.802     ]),\n",
              " 'split5_train_score': array([0.63541667, 0.85583333, 0.842     , 0.75391667, 0.82      ,\n",
              "        0.825     , 0.88483333, 0.91291667, 0.92783333, 0.813     ,\n",
              "        0.89208333, 0.87616667, 0.83858333, 0.861     , 0.86016667,\n",
              "        0.95758333, 0.93741667, 0.93425   , 0.96583333, 0.95375   ,\n",
              "        0.95208333, 0.95458333, 0.94      , 0.94558333, 0.96216667,\n",
              "        0.95475   , 0.95108333]),\n",
              " 'split6_test_score': array([0.736     , 0.48066667, 0.48666667, 0.66866667, 0.47866667,\n",
              "        0.46666667, 0.374     , 0.464     , 0.41733333, 0.544     ,\n",
              "        0.48133333, 0.47666667, 0.554     , 0.47066667, 0.45933333,\n",
              "        0.37866667, 0.45933333, 0.392     , 0.406     , 0.51466667,\n",
              "        0.47066667, 0.424     , 0.53066667, 0.52      , 0.52666667,\n",
              "        0.53866667, 0.534     ]),\n",
              " 'split6_train_score': array([0.67008333, 0.88866667, 0.88016667, 0.83875   , 0.86925   ,\n",
              "        0.86783333, 0.92483333, 0.92083333, 0.928     , 0.86233333,\n",
              "        0.903     , 0.90458333, 0.86958333, 0.88866667, 0.89308333,\n",
              "        0.93875   , 0.93175   , 0.93333333, 0.963     , 0.9535    ,\n",
              "        0.95383333, 0.95983333, 0.94641667, 0.94975   , 0.9575    ,\n",
              "        0.95433333, 0.9535    ]),\n",
              " 'split7_test_score': array([0.65      , 0.864     , 0.87533333, 0.96133333, 0.85533333,\n",
              "        0.87133333, 0.82866667, 0.84466667, 0.81266667, 0.86866667,\n",
              "        0.86533333, 0.85266667, 0.92266667, 0.868     , 0.85266667,\n",
              "        0.76533333, 0.81533333, 0.746     , 0.802     , 0.86533333,\n",
              "        0.82933333, 0.85066667, 0.83666667, 0.83533333, 0.83066667,\n",
              "        0.80533333, 0.768     ]),\n",
              " 'split7_train_score': array([0.61233333, 0.85716667, 0.86466667, 0.79475   , 0.82491667,\n",
              "        0.82716667, 0.89041667, 0.92591667, 0.9365    , 0.83933333,\n",
              "        0.90066667, 0.90608333, 0.8535    , 0.86216667, 0.86458333,\n",
              "        0.92066667, 0.94175   , 0.93808333, 0.95858333, 0.948     ,\n",
              "        0.95075   , 0.95725   , 0.944     , 0.94391667, 0.93633333,\n",
              "        0.95133333, 0.95708333]),\n",
              " 'split8_test_score': array([0.73866667, 0.78333333, 0.814     , 0.79266667, 0.83333333,\n",
              "        0.85      , 0.446     , 0.72333333, 0.71533333, 0.92866667,\n",
              "        0.74533333, 0.786     , 0.928     , 0.81333333, 0.828     ,\n",
              "        0.554     , 0.73466667, 0.74933333, 0.756     , 0.74333333,\n",
              "        0.724     , 0.70866667, 0.73666667, 0.748     , 0.75533333,\n",
              "        0.69133333, 0.694     ]),\n",
              " 'split8_train_score': array([0.55908333, 0.87191667, 0.87058333, 0.8065    , 0.85525   ,\n",
              "        0.85158333, 0.93      , 0.92641667, 0.91883333, 0.87866667,\n",
              "        0.89625   , 0.88216667, 0.88233333, 0.88025   , 0.87516667,\n",
              "        0.93233333, 0.94041667, 0.94033333, 0.96066667, 0.95091667,\n",
              "        0.959     , 0.95733333, 0.95225   , 0.95383333, 0.94425   ,\n",
              "        0.96158333, 0.95883333]),\n",
              " 'std_fit_time': array([0.01081777, 0.00285309, 0.00306257, 0.01929997, 0.00528176,\n",
              "        0.008408  , 0.13230504, 0.02110516, 0.04664027, 0.01503602,\n",
              "        0.00270811, 0.00403687, 0.01149608, 0.00405028, 0.00544181,\n",
              "        0.32140974, 0.01738492, 0.03665168, 0.0315772 , 0.00666044,\n",
              "        0.01182579, 0.05311932, 0.00873647, 0.0167006 , 0.61536739,\n",
              "        0.04275104, 0.08305094]),\n",
              " 'std_score_time': array([7.73526944e-05, 2.80143803e-05, 5.08939334e-04, 2.86537838e-05,\n",
              "        5.19312420e-05, 4.48799751e-05, 8.04064277e-05, 2.85899125e-05,\n",
              "        7.10008747e-05, 2.83458151e-05, 3.09733059e-05, 2.23827079e-05,\n",
              "        5.33648796e-05, 2.85014343e-05, 2.96657991e-05, 3.70958863e-05,\n",
              "        4.22798601e-05, 3.45960084e-05, 2.10746813e-05, 1.86576820e-05,\n",
              "        2.92133844e-05, 2.05347098e-05, 3.35364168e-05, 2.90281140e-05,\n",
              "        8.27925657e-05, 2.05158366e-05, 2.00344478e-05]),\n",
              " 'std_test_score': array([0.11016536, 0.12563247, 0.12028352, 0.14146884, 0.13360162,\n",
              "        0.13285152, 0.20575522, 0.13532127, 0.14090081, 0.13561092,\n",
              "        0.12502207, 0.11489345, 0.14441645, 0.13086606, 0.12651835,\n",
              "        0.18523804, 0.15293317, 0.1490974 , 0.1475097 , 0.12568705,\n",
              "        0.12496562, 0.13893212, 0.12411902, 0.12043492, 0.10159134,\n",
              "        0.11721417, 0.11548934]),\n",
              " 'std_train_score': array([0.02899305, 0.01064311, 0.01183236, 0.02954801, 0.01411305,\n",
              "        0.01370934, 0.01966009, 0.00512906, 0.00753511, 0.02014738,\n",
              "        0.00634694, 0.01155728, 0.01736998, 0.00913293, 0.01019691,\n",
              "        0.01066188, 0.00334622, 0.00278253, 0.00437594, 0.00389941,\n",
              "        0.00479422, 0.00394192, 0.00424872, 0.00373485, 0.00858665,\n",
              "        0.00573423, 0.00612448])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqP1XJVapGUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "434976a4-f29c-49ec-dd59-71f1dd83896f"
      },
      "source": [
        "#Best parameters\n",
        "gs.best_params_"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.05, 'loss': 'log', 'penalty': 'l1'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX22j7YrpJKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93bed339-06af-43cb-b5e5-9dffea11b767"
      },
      "source": [
        "#Best score\n",
        "gs.best_score_"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7776296296296297"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMc8_eH0pLxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c9d5fed9-c031-4e5b-fbf1-2b2c255aa25a"
      },
      "source": [
        "#Training the model with the best parameters\n",
        "bestclf = SGDClassifier(alpha= 0.05, loss= 'log', penalty= 'l1')\n",
        "bestclf.fit(X_train_selected, y_train)\n",
        "tr_p = bestclf.predict(X_train_selected)\n",
        "print(accuracy_score(y_train, tr_p))\n",
        "confusion_matrix(y_train, tr_p)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.831925925925926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2775,    0,    9,    0,    0],\n",
              "       [   8, 1764,    5,  290,  515],\n",
              "       [  91,    2, 2146,  407,    3],\n",
              "       [   0,    5,   56, 2389,   26],\n",
              "       [ 139,  539,    5,  169, 2157]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC1Pt9mSpQp5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "58a348c8-1be1-4f2f-e49d-5bc7d1f0be2e"
      },
      "source": [
        "#Running the model on the test set\n",
        "predictions = bestclf.predict(X_test_selected)\n",
        "print(accuracy_score(y_test, predictions))\n",
        "confusion_matrix(y_test, predictions)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7237783781221859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4406,   37,   12,    0,   11],\n",
              "       [   0, 3386,   31,  172,  813],\n",
              "       [2704,   13, 1919,   95,   48],\n",
              "       [   0,  223,    0, 2989,  702],\n",
              "       [   0,   60,   10,  897, 2571]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}